## Matching Massivo Otimizado com LSH**

### üìå **Objetivo**

Reduzir drasticamente o custo computacional do processo de *matching entre clientes* em um pipeline de segmenta√ß√£o e recomenda√ß√£o. O desafio consistia em substituir o self-join quadr√°tico (O(n¬≤)) tradicional por uma abordagem escal√°vel, sem comprometer a acur√°cia dos resultados.

---

### üß† **Contexto e Desafio**

O pipeline original realizava c√°lculos de similaridade entre todos os pares de clientes (self-join completo), para estimar proximidade com perfis comportamentais. Este processo, embora conceitualmente correto, se tornava **computacionalmente invi√°vel em bases m√©dias a grandes** (ex: 500k+ clientes), gerando gargalos cr√≠ticos de tempo e mem√≥ria.

Principais sintomas:

* Tempo de execu√ß√£o > 3h para bases m√©dias
* Spill frequente no disco
* Desempenho insatisfat√≥rio no Databricks

---

### üß™ **T√©cnicas Aplicadas**

#### 1. **Locality-Sensitive Hashing (LSH) com BucketedRandomProjection**

Utilizamos a t√©cnica de *aproxima√ß√£o vetorial probabil√≠stica* para encontrar pares similares sem verificar todas as combina√ß√µes.

```python
from pyspark.ml.feature import BucketedRandomProjectionLSH
from pyspark.ml.linalg import Vectors

# Vetoriza√ß√£o de atributos comportamentais
df = df.withColumn("features", array("ticket_medio", "frequencia", "recencia"))

# Convers√£o para formato vetorial
df = df.withColumn("features", udf(lambda arr: Vectors.dense(arr), VectorUDT())(col("features")))

# Instancia√ß√£o do modelo LSH
brp = BucketedRandomProjectionLSH(
    inputCol="features",
    outputCol="hashes",
    bucketLength=2.0,
    numHashTables=5
)

# Treinamento e matching aproximado
model = brp.fit(df)
similar_pairs = model.approxSimilarityJoin(df, df, threshold=1.5)
```

#### 2. **Amostragem Estratificada com `sampleBy`**

Reduzimos o universo de compara√ß√£o com **estrat√©gia de amostragem guiada por perfil nomeado**, garantindo representatividade e balanceamento.

```python
fractions = df.select("perfil_nomeado").distinct().rdd.flatMap(lambda x: x).map(lambda x: (x, 0.2)).collectAsMap()
sampled_df = df.sampleBy("perfil_nomeado", fractions)
```

#### 3. **Broadcast de Refer√™ncia de Perfis**

Para evitar o custo de joins completos, a base de perfis centrais foi convertida em **vari√°vel de broadcast**, reduzindo shuffle e melhorando paralelismo.

```python
profile_bc = spark.sparkContext.broadcast(profile_df.collect())
```

---

### ‚öôÔ∏è **Pipeline Final em Produ√ß√£o**

* Pr√©-processamento vetorial
* Matching com LSH (`approxSimilarityJoin`)
* Similaridade com `distCol` (Euclidean)
* P√≥s-processamento com pesos din√¢micos
* Nomea√ß√£o de perfis com regra vetorial + categorias dominantes

---

### üìà **Resultados e Benef√≠cios**

| M√©trica                         | Antes (Self-Join O(n¬≤))     | Depois (LSH) |
| ------------------------------- | --------------------------- | ------------ |
| Tempo de execu√ß√£o               | \~3 horas                   | < 18 minutos |
| Custo computacional (Spark UI)  | Alto (spill + shuffle)      | Baixo        |
| Qualidade dos matches (amostra) | 91% compat√≠vel com baseline | 89%          |
| Escalabilidade (1M+ clientes)   | Impratic√°vel                | Vi√°vel       |

---

### üß≠ **Conclus√£o Profissional**

A substitui√ß√£o do self-join por **LSH (Locality-Sensitive Hashing)** reduziu a complexidade do pipeline de O(n¬≤) para O(n¬∑logn), tornando o processo de matching escal√°vel e apropriado para cen√°rios produtivos com milh√µes de registros.

A estrat√©gia se mostrou robusta, mantendo alta acur√°cia (\~89‚Äì91%) mesmo com aproxima√ß√£o vetorial, e compat√≠vel com sistemas como **Databricks** com uso intensivo de mem√≥ria distribu√≠da e particionamento otimizado.

---

### üöÄ **Diferenciais T√©cnicos Demonstrados**

* Otimiza√ß√£o algor√≠tmica baseada em teoria de complexidade
* Aplica√ß√£o real de t√©cnicas probabil√≠sticas (LSH) para big data
* Engenharia de performance em ambientes distribu√≠dos
* Estrat√©gia de balanceamento entre custo e acur√°cia
* Profunda compreens√£o de vetoriza√ß√£o e broadcast no Spark
